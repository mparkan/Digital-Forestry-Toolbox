<!DOCTYPE html>
<html lang="en-us">
    <head>
        <meta charset="UTF-8">
        <title>DFT - Tutorial 2</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <link rel="shortcut icon" type="image/png" href="img/favicon_dft.png"/>
        <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
        <link rel='stylesheet' type='text/css' href='https://fonts.googleapis.com/css?family=Open+Sans:400,700'>
        <link rel='stylesheet' type='text/css' href='https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css' >
        <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
        <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
        <link rel="stylesheet" type="text/css" href="lib/ol-v5.3.0/ol.css" media="screen">
        <link rel="stylesheet" type="text/css" href="lib/ol-layerswitcher/ol-layerswitcher.css">

        <!--     <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.6.1/css/all.css" integrity="sha384-gfdkjb5BdAXd+lj+gudLWI+BXq4IuLW5IT+brZEZsLFm++aCMlF1V92rMkPaX4PP" crossorigin="anonymous">
-->
        <script src="lib/ol-v5.3.0/ol.js"></script>
        <script src="lib/proj4js-2.5.0/proj4.js"></script>
        <script src="lib/ol-layerswitcher/ol-layerswitcher.js"></script>
        <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async></script>

    </head>
    <body>

        <section class="page-header tutorial">
            <h1 class="project-name">Digital-Forestry-Toolbox</h1>
            <br>
            <!--<h2 class="project-tagline white">A collection of digital forestry tools for Matlab</h2>-->
            <a href="index.html" class="btn"><i class="fa fa-home" aria-hidden="true"></i> Back to homepage</a>
        </section>

        <section class="main-content">

            <h1>Individual tree crown detection using marker controlled watershed segmentation</h1>

            <p style="text-align: center"><i class="fa fa-info-circle fa-2x" aria-hidden="true"></i></p>
            <p style="text-align: center"><b>Published</b>: May 15, 2018 / <b>Last updated</b>: January 8, 2019</p>
            <p style="text-align: center"><b>Tested on Matlab r2017b, GNU Octave 4.4.1</b></p>

            <!--<p> In this tutorial, you will learn how to detect individual tree crowns from a raster Canopy Height Model (CHM) using marker controlled watershed segmentation.-->

            <!--            <h2>
<a id="introduction" class="anchor" href="introduction" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><b>Introduction</b>
</h2>

<div id="map1">

<iframe src='https://map.geo.admin.ch/embed.html?topic=ech&lang=fr&bgLayer=ch.swisstopo.swissimage&layers=ch.swisstopo.zeitreihen,ch.bfs.gebaeude_wohnungs_register,ch.bafu.wrz-wildruhezonen_portal,ch.swisstopo.swisstlm3d-wanderwege&layers_visibility=false,false,false,false&layers_timestamp=18641231,,,&zoom=9&E=2699827.20&N=1271114.60' width='100%' height='450' frameborder='0' style='border:0'></iframe>

</div>-->



            <h2>
                <a id="setup" class="anchor" href="setup" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><b>Setup</b>
            </h2>

            <ol>
                <li>Download and uncompress the Digital Forestry Toolbox (DFT) <a href="https://github.com/mparkan/Digital-Forestry-Toolbox/zipball/master">Zip</a> or <a href="https://github.com/mparkan/Digital-Forestry-Toolbox/tarball/master">Tar</a> archive</li>
                <li>Download the <a href="https://zenodo.org/record/1998192/files/zh_2014_a.laz?download=1">zh_2014_a.laz</a> file from the DFT Zenodo repository and uncompress it with <a href="http://www.laszip.org/">LASzip</a></li>
                <li>Start Matlab/Octave</li>
                <li>Delete any previous versions of the toolbox</li>
                <li>Add the DFT folders to the Matlab/Octave search path using <code>addpath(genpath('path to DFT main folder'))</code></li>
                <li>Open <code>dft_tutorial_2.m</code> (located in the tutorials folder)</li>
            </ol>

            <h2>
                <a id="step-1" class="anchor" href="step-1" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><b>Step 1</b> - Reading the LAS file
            </h2>

            <p>We start by reading the LAS file using <code>LASread()</code>:</p>

            <pre><code>pc = LASread('zh_2014_a.las');</code></pre>

            <p>Note that the point classification uses the following scheme:</p>

            <table>
                <thead>
                    <tr>
                        <th>Class</th>
                        <th>Description</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>2</td>
                        <td>Terrain</td>
                    </tr>
                    <tr>
                        <td>3</td>
                        <td>Low vegetation (< 50 cm)</td>
                    </tr>
                    <tr>
                        <td>4</td>
                        <td>Medium vegetation (< 3 m)</td>
                    </tr>
                    <tr>
                        <td>5</td>
                        <td>High vegetation (> 3 m)</td>
                    </tr>
                    <tr>
                        <td>6</td>
                        <td>Buildings</td>
                    </tr>
                    <tr>
                        <td>7</td>
                        <td>Outliers and incorrect measurements (Noise)</td>
                    </tr>
                    <tr>
                        <td>10</td>
                        <td>Bridges (> 3m)</td>
                    </tr>
                    <tr>
                        <td>12</td>
                        <td>Strip border points (Overlap)</td>
                    </tr>
                    <tr>
                        <td>15</td>
                        <td>Overhead lines, masts, antennae</td>
                    </tr>
                    <tr>
                        <td>17</td>
                        <td>Other (vehicles, etc. )</td>
                    </tr>
                </tbody>
            </table>


            <h2>
                <a id="step-2" class="anchor" href="step-2" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><b>Step 2</b> - Computing a raster Canopy Height Model (CHM)
            </h2>

            <p>We now build 0.8 m resolution raster elevation models from the classified 3D point cloud using <code>elevationModels()</code>:</p>


            <pre><code>cellSize = 0.8;
[models, refmat] = elevationModels([pc.record.x, pc.record.y, pc.record.z], ...
    pc.record.classification, ...
    'classTerrain', [2], ...
    'classSurface', [4,5], ...
    'cellSize', cellSize, ...
    'interpolation', 'idw', ...
    'searchRadius', inf, ...
    'weightFunction', @(d) d^-3, ...
    'smoothingFilter', fspecial('gaussian', [3, 3], 0.8), ...
    'outputModels', {'terrain', 'surface', 'height'}, ...
    'fig', true, ...
    'verbose', true);</code></pre>

            <p>Note that we have only used classes 4 (medium vegetation) and 5 (high vegetation) when computing the surface model (with the <code>'classSurface'</code> parameter). We've also applied a 3x3 pixel Gaussian lowpass filter (with the <code>'smoothingFilter'</code> parameter). The resulting CHM should look like this:</p>

            <figure>
                <img src="img/dft_tutorial_2_ima_1.png" alt="" style="width:90%;">
                <figcaption><b>Figure 1</b> - Raster canopy height model.</figcaption>
            </figure>


            <h2>
                <a id="step-3" class="anchor" href="step-3" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><b>Step 3</b> - Tree top detection
            </h2>


            <p>In this step, tree top (local maxima) detection is applied to the CHM. Following the method described in <a href="#references">Chen et al. (2006)</a>, a power law was used to describe the relation between crown radius and height. Non-linear regression was applied to a set of (manually delineated) reference observations, to determine the parameter values of the power law model (see figure 2). Subsequently, the lower 95% prediction bound of the regression was used as the mimimum separation (merging) range (r) between tree tops as a function of their height (h):</p>
            <!--            (n.b. this step is not covered in the tutorial)-->

            $$\DeclareMathOperator*{\max}{max}
            r(h) = 0.28 \cdot h^{0.59} $$

            <!--            $$\DeclareMathOperator*{\max}{max}
r(h) = 0.5 + 0.25 \cdot ln(\max_h(h,1)) $$-->

            <figure>
                <img src="img/dft_tutorial_2_crown_radius_mdl.png" alt="" style="width:90%;">
                <figcaption><b>Figure 2</b> - Crown radius as a function of height. The continuous red line represents the fitted power law model and the dashed lines represent the 95% prediction bounds for new observations.</figcaption>
            </figure>

            <p>This model or any other, e.g. <a href="#references">Popescu and Wynne (2004)</a>, can be specified for the <code>'searchRadius'</code> and/or <code>'mergeRadius'</code> parameters in the <code>canopyPeaks()</code> function. In this example, the function starts by searching for all local maxima that are higher than their 1 m neighbourhoud (i.e. <code>'searchRadius'</code> is 1 m). It then sorts these peaks by decreasing height and, starting from the highest peak, it sequentially removes all lower peaks that are within the merge radius (i.e. <code>'mergeRadius'</code> is 0.28*h^0.59 m) of their higher neighbours:</p>

            <pre><code>[peaks_crh, ~] = canopyPeaks(models.height.values, ...
    refmat, ...
    'minTreeHeight', 2, ..
    'searchRadius', @(h) 1, ...
    'mergeRadius', @(h) 0.28 * h^0.59, ...
    'fig', true, ...
    'verbose', true);</code></pre>

            <p>By modifing the <code>'searchRadius'</code> and/or <code>'mergeRadius'</code> parameters, you can adjust the tradeoff between the sensitivity (recall) and the reliability (precision) of the detection. The interactive map below illustrates the detected tree top positions.</p>

             <div id="map2"></div>


            <!--        <figure>
<img src="img/dft_tutorial_2_ima_2.png" alt="" style="width:90%;">
<figcaption><b>Figure 2</b> - Tree top detection.</figcaption>
</figure>-->

            <h2>
                <a id="step-4" class="anchor" href="step-4" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><b>Step 4</b> - Marker controlled watershed segmentation
            </h2>

            <p>Using the previously computed CHM, tree top coordinates and boolean mask, we now compute the marker controlled watershed segmentation with <code>treeWatershed()</code>:</p>

            <pre><code>[label_2d, colors] = treeWatershed(models.height.values, ...
    'markers', peaks_crh, ...
    'minHeight', 1, ...
    'removeBorder', true, ...
    'fig', true, ...
    'verbose', true);</code></pre>

            <p>Note that the "removeBorder" argument is set to true, to remove segments that touch the border of the image.</p>

            <p>The resulting label matrix should look like this:</p>


            <figure>
                <img src="img/dft_tutorial_2_ima_3.png" alt="" style="width:90%;">
                <figcaption><b>Figure 3</b> - Marker controlled watershed segmentation 2D labels. Note that the segments located on the edge of the CHM have been excluded due to the boolean mask we specified.</figcaption>
            </figure>


            <h2>
                <a id="step-5" class="anchor" href="step-5" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><b>Step 5</b> - Computing segment metrics from the label matrix
            </h2>

            <p>From the labelled matrix, it is possible to compute a set of basic features (note that some of the metrics in regionprops() are currently only available in Matlab):</p>

            <pre><code>metrics_2d = regionprops(label_2d, models.height.values, ...
    'Area', 'Centroid', 'MaxIntensity');</code></pre>


            <h2>
                <a id="step-6" class="anchor" href="step-6" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><b>Step 6</b> - Transferring 2D labels to the 3D point cloud
            </h2>

            <p>The next step is transferring the 2D labels and colors to the 3D point cloud:</p>

            <pre><code>idxl_veg = ismember(pc.record.classification, [4,5]);

% convert map coordinates (x,y) to image coordinates (column, row)
RC = [pc.record.x - refmat(3,1), pc.record.y - refmat(3,2)] / refmat(1:2,:);
RC(:,1) = round(RC(:,1)); % row
RC(:,2) = round(RC(:,2)); % column
ind = sub2ind(size(label_2d), RC(:,1), RC(:,2));

% transfer the label
label_3d = label_2d(ind);
label_3d(~idxl_veg) = 0;
[label_3d(label_3d ~= 0), ~] = grp2idx(label_3d(label_3d ~= 0));

% transfer the color index
color_3d = colors(ind);
color_3d(~idxl_veg) = 1;

% define a colormap
cmap = [0, 0, 0;
    166,206,227;
    31,120,180;
    178,223,138;
    51,160,44;
    251,154,153;
    227,26,28;
    253,191,111;
    255,127,0;
    202,178,214;
    106,61,154;
    255,255,153;
    177,89,40] ./ 255;</code></pre>

            <h2>
                <a id="step-7" class="anchor" href="step-7" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><b>Step 7</b> - Plotting the colored points cloud
            </h2>

            <br>
            <div class="box">

                <p style="text-align: center"><i class="fa fa-exclamation-triangle fa-2x" aria-hidden="true"></i></p>

                <b>Octave users</b>, due to 3D plotting performance issues, the display of large points clouds is currently discouraged.

            </div>
            <br>

            <p>To plot the complete colored point cloud, use:</p>

            <pre><code>if ~OCTAVE_FLAG

    figure('Color', [1,1,1])
    scatter3(pc.record.x(idxl_veg), ...
        pc.record.y(idxl_veg), ...
        pc.record.z(idxl_veg), ...
        6, ...
        color_3d(idxl_veg), ...
        'Marker', '.')
    axis equal tight
    colormap(cmap)
    caxis([1, size(cmap,1)])
    xlabel('x')
    ylabel('y')
    zlabel('z')

end</code></pre>

            <p>The result should look like this:</p>


            <figure>
                <img src="img/dft_tutorial_2_ima_4.png" alt="" style="width:90%;">
                <figcaption><b>Figure 4</b> - Marker controlled watershed segmentation 3D labels. Note that the segments located on the edge of the CHM have been excluded due to the boolean mask.</figcaption>
            </figure>


            <p> You can also plot any individual segment. For example segment n° 42:</p>

            <pre><code>if ~OCTAVE_FLAG

    idxl_sample = (label_3d == 42);
    figure
    scatter3(pc.record.x(idxl_sample), ...
        pc.record.y(idxl_sample), ...
        pc.record.z(idxl_sample), ...
        12, ...
        pc.record.intensity(idxl_sample), ...
        'Marker', '.');
    colorbar
    axis equal tight
    title('Return intensity')
    xlabel('x')
    ylabel('y')
    ylabel('z')

end</code></pre>

            <figure>
                <img src="img/dft_tutorial_2_ima_5.png" alt="" style="width:90%;">
                <figcaption><b>Figure 5</b> - 3D segment n°42 colored by return intensity.</figcaption>
            </figure>


            <h2>
                <a id="step-8" class="anchor" href="step-8" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><b>Step 8</b> - Computing segment metrics from the labelled point cloud
            </h2>

            <p>We now compute descriptive metrics directly from the point cloud for each segment using <code>treeMetrics()</code>:</p>

            <pre><code>metrics_3d = treeMetrics(label_3d, ...
                    [pc.record.x, pc.record.y, pc.record.z], ...
                    pc.record.intensity, ...
                    pc.record.return_number, ...
                    pc.record.number_of_returns, ...
                    nan(length(pc.record.x), 3), ...
                    models.terrain.values, ...
                    refmat, ...
                    'metrics', {'all'}, ...
                    'intensityScaling', true, ...
                    'dependencies', false, ...
                    'scalarOnly', true, ...
                    'verbose', true);
</code></pre>

            <h2>
                <a id="step-9" class="anchor" href="step-9" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><b>Step 9</b> - Exporting the segment metrics to CSV and SHP files
            </h2>

            <p>The following illustrates how to export the segmentation metrics to a Comma Separated Values text file (.csv). You first have to convert the <code>metrics_3d</code> structure to a cell array:</p>

            <pre><code>fields = fieldnames(metrics_3d);
m = length(fields);
n = length(metrics_3d.(fields{1}));

% determine print format
idxl_num = structfun(@(x) isnumeric(x), metrics_3d);
fmt = repmat({'%s'}, [1 m]);
fmt(idxl_num) = {'%.3f'};
fmt = [strjoin(fmt, ','), '\n'];

% convert structure to cell array
C = cell(m, n);
for j = 1:m

    if isnumeric(metrics_3d.(fields{j}))

        C(j,:) = num2cell(metrics_3d.(fields{j}));

    else

        C(j,:) = metrics_3d.(fields{j});

    end

end</code></pre>

            <p>You can then write the data to a CSV file with:</p>

            <pre><code>% write cell array to CSV file
% IMPORTANT: adjust the path to the output CSV file
fid = fopen('zh_2014_a_seg_metrics.csv', 'w+'); % open file
fprintf(fid, '%s\n', strjoin(fields, ',')); % write header line
fprintf(fid, fmt, C{:}); % write metrics
fclose(fid); % close file</code></pre>

            <p>After exporting the CSV file, you can try opening it in any text editor (e.g. <a href="https://notepad-plus-plus.org/">Notepad++</a>).</p>

            <p>To export the segmentation metrics to an ESRI shapefile you first have to convert the cell array <code>C</code> to a non-scalar structure and add a "Geometry" field:</p>

            <pre><code>% create a non-scalar structure
S = cell2struct(C, fields);
clear C

% add geometry field
[S.Geometry] = deal('Point');</code></pre>

            <br>
            <div class="box">

                <p style="text-align: center"><i class="fa fa-exclamation-triangle fa-2x" aria-hidden="true"></i></p>

                <b>Octave users</b>, please make sure you are using the latest versions of the <a href="https://sourceforge.net/p/octave/io/ci/default/tree/"><b>'io' (2.4.12 or above)</b></a> and <a href="https://sourceforge.net/p/octave/mapping/ci/default/tree/"> <b>'mapping' (1.4.0 snapshot or above)</b></a> packages. Previous versions contain critical issues in the shapewrite function.

            </div>
            <br>

            <p>Then use <code>shapewrite()</code> to write the file:</p>

            <pre><code>% write non-scalar structure to SHP file
% IMPORTANT: adjust the path to the output SHP file
shapewrite(S, 'zh_2014_a_seg_metrics.shp');</code></pre>


            <p>After exporting the SHP file, you can try opening it in any GIS software (e.g. <a href="http://www.qgis.org">Quantum GIS</a>).</p>

            <h2>
                <a id="step-10" class="anchor" href="step-10" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><b>Step 10</b> - Exporting the labelled and colored point cloud to a LAS 1.4 file
            </h2>


            <p>Finally, we export the colored point cloud to a LAS 1.4 file with <code>LASwrite()</code>. We start by duplicating the source file and adding the RGB records:</p>


            <pre><code>% duplicate the source file
r = pc;

% rescale the RGB colors to 16 bit range and add them to the point record
rgb = uint16(cmap(color_3d,:) * 65535);
r.record.red = rgb(:,1);
r.record.green = rgb(:,2);
r.record.blue = rgb(:,3);</code></pre>

            <p>We then add the "label" as an extra 32 bit record and add the metadata for this field in the Variable Length Records (cf. <a href="https://www.asprs.org/a/society/committees/standards/LAS_1_4_r13.pdf">ASPRS LAS 1.4 specification</a> for details about the meaning of the metadata fields):</p>

            <pre><code>% add the "label" field to the point record (as an uint32 field)
r.record.label = uint32(label_3d);

% add the "label" uint32 field metadata in the variable length records
% check the ASPRS LAS 1.4 specification for details about the meaning of the fields
% https://www.asprs.org/a/society/committees/standards/LAS_1_4_r13.pdf
vlr = struct;
vlr.value.reserved = 0;
vlr.value.data_type = 5;
vlr.value.options.no_data_bit = 0;
vlr.value.options.min_bit = 0;
vlr.value.options.max_bit = 0;
vlr.value.options.scale_bit = 0;
vlr.value.options.offset_bit = 0;
vlr.value.name = 'label';
vlr.value.unused = 0;
vlr.value.no_data = [0; 0; 0];
vlr.value.min = [0; 0; 0];
vlr.value.max = [0; 0; 0];
vlr.value.scale = [0; 0; 0];
vlr.value.offset = [0; 0; 0];
vlr.value.description = 'LABEL';

vlr.reserved = 43707;
vlr.user_id = 'LASF_Spec';
vlr.record_id = 4;
vlr.record_length_after_header = length(vlr.value) * 192;
vlr.description = 'Extra bytes';

% append the new VLR to the existing VLR
if isfield(r, 'variable_length_records')

    r.variable_length_records(length(r.variable_length_records)+1) = vlr;

else

    r.variable_length_records = vlr;

end</code></pre>

            <p>We also adjust the point data record format in the LAS header to support the RGB fields:</p>

            <pre><code>% if necessary, adapt the output record format to add the RGB channel
switch pc.header.point_data_format_id

    case 1 % 1 -> 3

        recordFormat = 3;

    case 4 % 4 -> 5

        recordFormat = 5;

    case 6 % 6 -> 7

        recordFormat = 7;

    case 9 % 9 -> 10

        recordFormat = 10;

    otherwise % 2,3,5,7,8,10

        recordFormat = pc.header.point_data_format_id;

end</code></pre>

            <p>Finally, we write the LAS file with <code>LASwrite()</code> and check that it has been correctly written with <code>LASread()</code>:</p>
            <pre><code>% write the LAS 1.4 file
% IMPORTANT: adjust the path to the output LAS file
LASwrite(r, ...
    'zh_2014_a_ws_seg.las', ...
    'version', 14, ...
    'guid', lower(strcat(dec2hex(randi(16,32,1)-1)')), ...
    'systemID', 'SEGMENTATION', ...
    'recordFormat', recordFormat, ...
    'verbose', true);

% you can optionally read the exported file and check it has the
% RGB color and label records
% IMPORTANT: adjust the path to the input LAS file
r2 = LASread('zh_2014_a_ws_seg.las');</code></pre>

            <p>After exporting, you can try opening the LAS file in any appropriate CAD, GIS or 3D visualization software (e.g. <a href="http://c42f.github.io/displaz/">Displaz</a>, <a href="http://www.danielgm.net/cc/">CloudCompare</a>, <a href="https://www.fugro.com/about-fugro/our-expertise/technology/fugroviewer">FugroViewer</a>).</p>


            <h2>
                <a id="references" class="anchor" href="references" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><b>References</b>
            </h2>

            <ul>
                <li>Chen, Q., Baldocchi, D., Gong, P., Kelly, M., 2006. <a href="https://www.ingentaconnect.com/content/asprs/pers/2006/00000072/00000008/art00003?crawler=true&mimetype=application/pdf">Isolating Individual Trees in a Savanna Woodland Using Small Footprint Lidar Data</a>. Photogrammetric Engineering and Remote Sensing 72, 923–932. https://doi.org/10.14358/PERS.72.8.923</li>

                <li>Kwak, D.-A., Lee, W.-K., Lee, J.-H., Biging, G.S., Gong, P., 2007. <a href="https://www.tandfonline.com/doi/abs/10.1007/s10310-007-0041-9">Detection of individual trees and estimation of tree height using LiDAR data</a>. Journal of Forest Research 12, 425–434. https://doi.org/10.1007/s10310-007-0041-9</li>

                <li>Meyer, F., 1994. <a href="https://perso.telecom-paristech.fr/bloch/P6Image/Projets/Watersnakes/meyer1994.pdf">Topographic distance and watershed lines</a>. Signal Processing, Mathematical Morphology and its Applications to Signal Processing 38, 113–125. https://doi.org/10.1016/0165-1684(94)90060-4</li>

                <li>Meyer, F., Beucher, S., 1990. <a href="http://www.cmm.mines-paristech.fr/~beucher/publi/Morphological_Segmentation.pdf">Morphological segmentation</a>. Journal of Visual Communication and Image Representation 1, 21–46. https://doi.org/10.1016/1047-3203(90)90014-M</li>

                <li>Pitkänen, J., Maltamo, M., Hyyppä, J., Yu, X., 2004. <a href="http://www.isprs.org/proceedings/XXXVI/8-W2/PITKAENEN.pdf">Adaptive methods for individual tree detection on airborne laser based canopy height model</a>. International Archives of Photogrammetry, Remote Sensing and Spatial Information Sciences 36, 187–191.</li>

                <li>Popescu, S.C., Wynne, R.H., 2004. <a href="https://www.ingentaconnect.com/content/asprs/pers/2004/00000070/00000005/art00003">Seeing the trees in the forest: Using lidar and multispectral data fusion with local filtering and variable window size for estimating tree height</a>. Photogrammetric Engineering and Remote Sensing 70, 589–604.</li>

                <li>Soille, P., 2013. Morphological image analysis: principles and applications. Springer Science & Business Media, Berlin, Germany.</li>

            </ul>

            <footer class="site-footer">
                <span class="site-footer-owner"><a href="https://github.com/mparkan/Digital-Forestry-Toolbox">Digital-forestry-toolbox</a> is maintained by <a href="https://github.com/mparkan">mparkan</a>.</span>

            </footer>

        </section>


        <script>

            // add CH1903 and CH1903+ CRS definitions
            if (proj4) {
                proj4.defs("EPSG:21781","+proj=somerc +lat_0=46.95240555555556 +lon_0=7.439583333333333 +k_0=1 +x_0=600000 +y_0=200000 +ellps=bessel +towgs84=674.4,15.1,405.3,0,0,0,0 +units=m +no_defs");
                proj4.defs("EPSG:2056", "+proj=somerc +lat_0=46.95240555555556 +lon_0=7.439583333333333 +k_0=1 +x_0=2600000 +y_0=1200000 +ellps=bessel +towgs84=674.374,15.056,405.346,0,0,0,0 +units=m +no_defs");
                ol.proj.proj4.register(proj4);
            };

            // define tile grid
            var extent = [2699499.7000000001862645, 1270999.8000000000465661, 2700000.2000000001862645, 1271500.3000000000465661]; // [minx, miny, maxx, maxy].
            var minZoom = 0;
            var maxZoom = 5;
            var startResolution = (extent[2]-extent[0]) / 256;
            var pixelResolutions = new Array(maxZoom + 1);
            for (var i = 0, ii = pixelResolutions.length; i < ii; ++i) {
                pixelResolutions[i] = startResolution / Math.pow(2, i);
            }
            var mapTileGrid = new ol.tilegrid.TileGrid({
                extent: extent,
                resolutions: pixelResolutions
            });

            // define vector layer
            var vectorLayer1 = new ol.layer.Vector({
                title: 'Tree tops',
                type: 'overlay',
                source: new ol.source.Vector({
                    format: new ol.format.GeoJSON(),
                    url: 'http://mparkan.github.io/Digital-Forestry-Toolbox/data/tutorial_2/vector/zh_2014_a_peaks.geojson',
                    crossOrigin: 'anonymous',
                    projection: 'EPSG:2056',
                }),
                style: new ol.style.Style({
                    image: new ol.style.Circle( ({
                        radius: 2,
                        fill: new ol.style.Fill({
                            color: '#ffff00'
                        })
                    }))
                })
            });

            // define XYZ tiles layer
            var rasterTileLayer1 = new ol.layer.Tile({
                title: 'Near infrared image',
                type: 'base',
                source: new ol.source.XYZ({
                    url: 'http://mparkan.github.io/Digital-Forestry-Toolbox/data/tutorial_2/raster/ortho_nir/{z}/{x}/{y}.jpg',
                    crossOrigin: 'anonymous',
                    tileGrid: mapTileGrid,
                    projection: 'EPSG:2056',
                    opaque: false,
                    attributions: ['Data courtesy of <a href=https://maps.zh.ch/>Kanton Zürich</a>']
                })
            });


            // define static image layer
            var rasterStaticLayer1 = new ol.layer.Image({
                title: 'Canopy Height Model',
                type: 'base',
                source: new ol.source.ImageStatic({
                    url: 'http://mparkan.github.io/Digital-Forestry-Toolbox/data/tutorial_2/raster/dhm/zh_2014_a_dhm.jpg',
                    crossOrigin: 'anonymous',
                    projection: 'EPSG:2056',
                    imageSize: [626,626],
                    imageExtent: extent,
                    attributions: 'Data courtesy of <a href=https://maps.zh.ch/>Kanton Zürich</a>'
                })
            });


            // define scale bar control
            var scaleLineControl = new ol.control.ScaleLine();

            // define attribution control
            var attributionControl = new ol.control.Attribution({
                collapsible: true,
                className: 'ol-attribution'
            });

            // define fullscreen control
            var icon1 = document.createElement("expand_icon");
            icon1.className = "fa fa-expand";

            var fullScreenControl = new ol.control.FullScreen({
                label: icon1
            });

            // layer switcher control
            var layerSwitcherControl = new ol.control.LayerSwitcher({
                tipLabel: 'Layers'
            });


            var layerGroup1 = new ol.layer.Group({
                title: 'Basemaps',
                layers: [
                    rasterTileLayer1,
                    rasterStaticLayer1
                ]
            });


            var layerGroup2 = new ol.layer.Group({
                title: 'Overlays',
                layers: [
                    vectorLayer1
                ]
            });


            // initialize map
            var map = new ol.WebGLMap({
                target: 'map2',
                controls: ol.control.defaults({attribution: false}).extend([
                    scaleLineControl,
                    attributionControl,
                    fullScreenControl,
                    layerSwitcherControl
                ]),
                interactions: ol.interaction.defaults().extend([
                    new ol.interaction.DragRotateAndZoom()
                ]),
                layers: [
                    layerGroup1,
                    layerGroup2
                ],
                view: new ol.View({
                    extent: extent,
                    center: ol.extent.getCenter(extent),
                    projection: ol.proj.get('EPSG:2056'),
                    zoom: 2,
                    minZoom: 1,
                    maxZoom: 6,
                    maxResolution: mapTileGrid.getResolution(minZoom)
                })
            });


        </script>


    </body>
</html>
