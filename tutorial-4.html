<!DOCTYPE html>
<html lang="en-us">
    <head>
        <meta charset="UTF-8">
        <title>DFT - Tutorial 4</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <link rel="shortcut icon" type="image/png" href="img/favicon_dft.png"/>
        <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
        <link rel='stylesheet' type='text/css' href='https://fonts.googleapis.com/css?family=Open+Sans:400,700'>
        <link rel='stylesheet' type='text/css' href='https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css' >
        <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
        <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
        <link rel="stylesheet" type="text/css" href="lib/ol-v5.3.0/ol.css" media="screen">
        <link rel="stylesheet" type="text/css" href="lib/ol-layerswitcher/ol-layerswitcher.css">

        <!--     <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.6.1/css/all.css" integrity="sha384-gfdkjb5BdAXd+lj+gudLWI+BXq4IuLW5IT+brZEZsLFm++aCMlF1V92rMkPaX4PP" crossorigin="anonymous">
-->
        <script src="lib/ol-v5.3.0/ol.js"></script>
        <script src="lib/proj4js-2.5.0/proj4.js"></script>
        <script src="lib/ol-layerswitcher/ol-layerswitcher.js"></script>
        <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async></script>

        <style>
            .map:-moz-full-screen {
                height: 100%;
            }
            .map:-webkit-full-screen {
                height: 100%;
            }
            .map:-ms-fullscreen {
                height: 100%;
            }
            .map:fullscreen {
                height: 100%;
            }
            /* position the rotate control lower than usual */
            .ol-rotate {
                top: 3em;
            }
        </style>

    </head>

    <body>

        <section class="page-header tutorial">
            <h1 class="project-name">Digital-Forestry-Toolbox</h1>
            <br>
            <!--<h2 class="project-tagline white">A collection of digital forestry tools for Matlab</h2>-->
            <a href="index.html" class="btn"><i class="fa fa-home" aria-hidden="true"></i> Back to homepage</a>
        </section>

        <section class="main-content">

            <h1>Deciduous/evergreen foliage classification</h1>

            <p style="text-align: center"><i class="fa fa-info-circle fa-2x" aria-hidden="true"></i></p>
            <p style="text-align: center"><b>Published</b>: April 10, 2019 / <b>Last updated</b>: April 10, 2019</p>
            <p style="text-align: center"><b>Tested on Matlab r2017b, GNU Octave 4.4.1</b></p>

            <h2>
                <a id="introduction" class="anchor" href="introduction" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><b>Introduction</b>
            </h2>

            <p>This tutorial presents a simple approach to differentiate deciduous and evergreen foliage using the calibrated/corrected return intensity of Airborne Laser Scanning (ALS) data. Foliage persistance maps can for example be useful to improve stem diameter prediction (by applying deciduous/evergreen specific allometric models) and for wildlife habitat modelling. This distinction is <b>not to be confused with the distinction of broadleaf and coniferous</b>, as some coniferous trees, such as larches, will shed their needles in automn while some broadleaf trees, such as hollies, will keep their leaves in winter.</p> 
            <p>Dense foliage and large branches have a higher probability of completely intercepting the laser beam and generating single high intensity returns (see figures 1 and 2). Moreover, most LiDAR systems employ near infrared light which is strongly reflected by live foliage. Thus, ALS data acquired during leaf-off conditions can be readily used to differentiate deciduous and evergreen foliage. It has also been repeatedly demonstrated that the return intensity and ranking distributions of laser scans are important features to differentiate tree species (e. g. <a href="#references">Liang et al., 2007; Ørka et al. 2009; Shi et al., 2018</a>).</p>  
            
            <br>
            <figure>
                <img src="img/dft_tutorial_4_ima_1a.png" alt="" style="width:80%;">
                <figcaption><b>Figure 1</b> - Conceptual example of the opacity difference under leaf-off conditions between birch (left) and spruce (right) trees. Low structural opacity will typically result in multiple low intensity returns. On the contrary, high structural opacity will tend to result in fewer high intensity returns.</figcaption>
            </figure>
            
            <figure>
                <img src="img/dft_tutorial_4_ima_2.png" alt="" style="width:80%;">
                <figcaption><b>Figure 2</b> - Example of difference in return intensity between a birch (left) and a spruce (right) tree in leaf-off conditions. Data courtesty of Geneva state (2017).</figcaption>
            </figure>
            <br>
            
            <!--
            <figure>
                <div id="image-table" style="width:100%;margin:auto">
                    <table>
                        <tr>
                            <td style="padding:5px;border:none">
                                <img src="img/dft_tutorial_4_ima_2a.png" alt="" style="width:85%;">
                            </td>

                            <td style="padding:5px;border:none">
                                <img src="img/dft_tutorial_4_ima_2b.png" alt="" style="width:85%;">
                            </td>
                        </tr>
                    </table>
                </div>
                <figcaption><b>Figure 2</b> - Example of difference in return intensity between a birch (left) and a spruce (right) tree in leaf-off conditions. Data courtesty of Geneva state (2017).</figcaption>
            </figure>
            <br>
            -->


             <p>However, due to various instrumental and environmental effects, the raw intensity is generally inconsistent accross the surveyed area and cannot be directly used as a discriminative feature; it should first be calibrated/corrected (<a href="#references">Vain and Kaasalainen, 2011; Kashani et al., 2015</a>). This can be a complex task, as the return intensity depends on parameters which can be difficult to estimate, as shown in the RaDAR/LiDAR range equation below:</p>
            
            <br>
            
<!--
            <p>. In theory, it is possible to determine the reflectance of the target surface, as shown in the RaDAR/LiDAR range equation below:</p>   
                
-->
            
            $$P_r = \frac{D_{r}^2 \eta_{atm} \eta_{sys} \sigma P_t}{4 \pi R^4 \beta_{t}^2 }$$

            $$\sigma = \frac{4 \pi}{\Omega} \rho A_t$$
        
        
            <p>where:</p>

            <ul style="list-style-type:none">
                <li> \(P_r\) is the received power [W];</li>
                <li> \(P_t\) is the transmitted power [W];</li>
                <li> \(D_r\) is the aperture diameter [m];</li>
                <li> \(\eta_{atm}\) is the atmospheric transmittance;</li>
                <li> \(\eta_{sys}\) is the system transmittance;</li>
                <li> \(\sigma\) is the effective target cross-section [m<sup>2</sup>];</li>
                <li> \(R\) is the range from sensor to target [m];</li>
                <li> \(\beta_{t}\) is the width of the laser beam [m];</li>
                <li> \(\Omega\) is the scattering solid angle [sr];</li>
                <li> \(\rho\) is the reflectance of the target;</li>
                <li> \(A_t\) is the area of the target [m<sup>2</sup>].</li>
            </ul>
            
            <p>The <a href="https://en.wikipedia.org/wiki/Reflectance reflectance">reflectance</a> (&rho;) - a measure of a surface's tendency to reflect incoming energy - is the value we would like to estimate. It can be isolated, by rearanging the terms of the RaDAR/LiDAR range equation:</p> 
            
            $$\rho = \frac{P_r R^4 \beta_{t}^2}{D_{r}^2 \eta_{atm} \eta_{sys} P_t A_t}$$
            
            
            <p>Moreover, this equation assumes that the target is a <a href="https://en.wikipedia.org/wiki/Lambertian_reflectance">Lambertian surface</a> and that the entire laser beam is intercepted. Both of these assumptions are invalid when measuring forests.</p>
            
            
            
            <p>ALS systems generally offer the possibility to apply some form of intensity correction in their proprietary post-processing software. Riegl's RiProcess software, for example, lets you export either the amplitude (range dependent value) or a range corrected value called reflectance to the "intensity" field in LAS files.</p>
            
            
            <p>This model shows that the range between the sensor and the target surface has a large influence on the measured intensity. To compensate the decay of intensity with range, a correction can be applied, if the trajectory and timing are known, following for example the guidelines provided in <a href="#references">Luzum et al. (2004)</a>.</p>
            
        
            $$I_{n} = I \cdot \left(\frac{r}{r_{ref}}\right)^2$$


            <p>where:</p>
        
            <ul style="list-style-type:none">
                <li> \(I_n\) is the normalized intensity;</li>
                <li> \(I\) is the raw intensity;</li>
                <li> \(r\) is the range between the sensor and the point;</li>
                <li> \(r_{ref}\) is an arbitrary constant reference range (e.g. 1000 m).</li>
            </ul>
        
  
            
            
            
            
            <p>Many LiDAR instruments have a high dynamic range meaning the ratio of the minimum and maximum measurable intensity (also called amplitude) value is very large and may span several orders of magnitude (<a href="#references">Riegl Laser Measurement Systems, 2017</a>). Thus, it is common to use decibel units (i.e. a logarithmic scale) to represent the intensity:</p> 
        
        
            $$I [dB] = 10 \cdot log_{10}\bigg(\frac{P}{P_{ref}}\bigg)$$
        
            <p>where:</p>
        
             <ul style="list-style-type:none">
                <li> \(P_t\) is the transmitted power [W];</li>
                <li> \(P_{ref}\) is the minimum detectable power [W].</li>
            </ul>
        
            <p>A relatively standard procedure found across LiDAR software is to apply a scale and offset transformation to the original intensity values to fit the 16 bit (0-65535) storage range used in the LAS format. The scaled value can be unscaled, using the following formula:</p>


            $$v_u = \frac{(v_{max}-v_{min}) \cdot v_s}{65535} + v_{min}$$

            <p>where:</p>
        
             <ul style="list-style-type:none">
                <li> \(v_u\) is the unscaled value;</li>
                <li> \(v_s\) is the scaled value;</li>
                <li> \(v_{max}\) is the maximum value;</li>
                <li> \(v_{min}\) is the minimum value.</li>
            </ul>
        
        <p>Using this procedure, the data used in this tutorial acquired with the RIEGL LMS-Q1560 was scaled using a minimum value of -20.0 dB and a maximum value of 15.0 dB. Thus, for example, a value of 24'000 in the LAS file can be unscaled using:</p>


            $$v_u = \frac{(15 + 20) \cdot 24000}{65535} -15 = -2.182 \quad [dB]$$

            

            
<!--
            <p>This tutorial assumes that:</p>
            <ol>
                <li>The data was acquired in leaf-off conditions</li>
                <li>The return intensity was calibrated and corrected</li>
            </ol>

            <p>The range between the sensor and the target surface has a large influence on the measured intensity, as shown in the RaDAR/LiDAR range equation below:</p>


            <p>Thus, raw ALS intensity cannot be used directly as a classification feature; it must first be calibrated/corrected (Vain and Kaasalainen, 2011; Kashani et al., 2015). A range correction can easily be applied, if the trajectory and timing are known, following for example the guidelines provided in Luzum et al. (2004).</p>
-->

            <!--Automatic Gain Control (AGC)-->

<!--<p>Riegl LiDAR software allows exporting either the amplitude (range dependent value) or a range corrected value called reflectance to the "intensity" LAS field. For the datasets acquired with the Riegl LMS-Q1560, the intensity stored in the LAS files is the reflectance (i.e. range independent value) scaled to a 16 bit range (0-65535) (<a href="#references">Riegl Laser Measurement Systems, 2017</a>).</p> -->
        
                    <p>In this tutorial, we will use data acquired over the state of Geneva (Switzerland) in February 2017 (leaf-off conditions) with the <a href="http://www.riegl.com/nc/products/airborne-scanning/"> Riegl LMS-Q1560</a> sensor. The data is openly available from <a href="https://ge.ch/sitg/donnees">Geneva's Official Geodata Portal</a>. Riegl's RiProcess post-processing software allows exporting either the amplitude (range dependent value) or a range corrected value called reflectance to the "intensity" LAS field. In the Geneva dataset used here, the intensity stored in the LAS file is the reflectance (i.e. range independent value) scaled to a 16 bit range (0-65535).</p> 
                        
                        
                        A small forest located about 10 km to the North of Geneva city (see map below) will serve as our study case. Within this area, the main tree species are pedunculate oak (<i>Quercus robur</i>) and Scots pine (<i>Pinus sylvestris</i>).</p>

            <div id="map1">

                <iframe src='https://map.geo.admin.ch/embed.html?topic=ech&lang=en&bgLayer=ch.swisstopo.swissimage&layers=ch.swisstopo.zeitreihen,ch.bfs.gebaeude_wohnungs_register,ch.bav.haltestellen-oev,ch.swisstopo.swisstlm3d-wanderwege&layers_visibility=false,false,false,false&layers_timestamp=18641231,,,&E=2499604.02&N=1127554.43&zoom=8' width='100%' height='450' frameborder='0'></iframe>

            </div>
        

            <h2>
                <a id="setup" class="anchor" href="setup" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><b>Setup</b>
            </h2>

            <ol>
                <li>Download and uncompress the Digital Forestry Toolbox (DFT) <a href="https://github.com/mparkan/Digital-Forestry-Toolbox/zipball/master">Zip</a> or <a href="https://github.com/mparkan/Digital-Forestry-Toolbox/tarball/master">Tar</a> archive</li>
                <li>Download the <a href="https://zenodo.org/record/1998192/files/ge_2017_a.laz?download=1">ge_2017_a.laz</a> file from the DFT Zenodo repository and uncompress it with <a href="http://www.laszip.org/">LASzip</a></li>
                <li>Start Matlab/Octave</li>
                <li>Delete any previous versions of the toolbox</li>
                <li>Add the DFT folders to the Matlab/Octave search path using <code>addpath(genpath('path to DFT main folder'))</code></li>
                <li>Open <code>dft_tutorial_4.m</code> (located in the tutorials folder)</li>
            </ol>

            <h2>
                <a id="step-1" class="anchor" href="step-1" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><b>Step 1</b> - Reading the LAS file
            </h2>

            <p>We start by reading the LAS file using <code>LASread()</code>:</p>

            <pre><code>pc = LASread('ge_2017_a.las');

xyz = [pc.record.x, pc.record.y, pc.record.z];
intensity = double(pc.record.intensity);</code></pre>

            <p>Note that you may have to adjust the file path in the code above, depending on where you are storing the LAS file. Also note that the point classification uses the following scheme:</p>

            <table>
                <thead>
                    <tr>
                        <th>Class</th>
                        <th>Description</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>0</td>
                        <td>Created, never lassified</td>
                    </tr>
                    <tr>
                        <td>1</td>
                        <td>Unclassified</td>
                    </tr>
                    <tr>
                        <td>2</td>
                        <td>Terrain</td>
                    </tr>
                    <tr>
                        <td>3</td>
                        <td>Low vegetation (&lt; 50 cm)</td>
                    </tr>
                    <tr>
                        <td>5</td>
                        <td>High vegetation (&ge; 50 cm)</td>
                    </tr>
                    <tr>
                        <td>6</td>
                        <td>Buildings</td>
                    </tr>
                    <tr>
                        <td>7</td>
                        <td>Outliers and incorrect measurements (Low noise)</td>
                    </tr>
                    <tr>
                        <td>9</td>
                        <td>Water</td>
                    </tr>

                    <tr>
                        <td>13</td>
                        <td>Bridges</td>
                    </tr>
                    <tr>
                        <td>15</td>
                        <td>Terrain (additional points)</td>
                    </tr>
                    <tr>
                        <td>16</td>
                        <td>Outliers and incorrect measurements (High noise)</td>
                    </tr>
                    <tr>
                        <td>19</td>
                        <td>Points measured outside of the area of interest (unclassified)</td>
                    </tr>
                </tbody>
            </table>


            <h2>
                <a id="step-2" class="anchor" href="step-2" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><b>Step 2</b> - Filter the points by classification and return number
            </h2>


            <p>In this step we create a filter which selects only last returns from the points within the high vegetation class:

            <pre><code>idxl_first = pc.record.return_number == 1;
idxl_veg = ismember(pc.record.classification, [5]);
idxl_filter = idxl_veg & idxl_first;</code></pre>


            <h2>
                <a id="step-3" class="anchor" href="step-3" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><b>Step 3</b> - Compute an intensity map
            </h2>

            <p> We now rasterize the points using a 1x1 m grid and compute the mean intensity of first returns in each cell, using the <code>rasterize()</code> function:</p>
        
            <pre><code>intensity(~idxl_filter) = nan;
cellSize = 1;

[I_first, refmat, ~] = rasterize(xyz(:,1:2), ...
    intensity, ...
    'cellSize', cellSize, ...
    'fun', @nanmean, ...
    'fill', nan, ...
    'fig', false);
</code></pre>

        <p>The resuling raster can be displayed with:</p>
        
        <pre><code>figure
imagesc(I_first);
axis equal tight
colorbar
caxis(quantile(I_first(:), [0.02, 0.98]))</code></pre>

        <p>Notice that the resulting intensity map is somewhat noisy due to the presence of small high intensity spots (near tree stems). You can optionally export the intensity map to an ARC/INFO ASCII grid file with the <code>ASCwrite()</code> function:</p>
        

<pre><code>ASCwrite('ge_2017_a_intensity.asc', ...
    I_first, ...
    refmat, ...
    'precision', 2, ...
    'noData', -99999, ...
    'verbose', true);</code></pre>
        
        
            <h2>
                <a id="step-4" class="anchor" href="step-4" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><b>Step 4</b> - Superpixel segmentation
            </h2>
        
            <p>One possible approach to smooth the intensity map we obtained in the preious step is to apply segmentation and average the intensity in each segment. The Simple Linear Iterative Clustering (SLIC) algorithm proposed by <a href="#references">Achanta et al. (2012)</a> is a well suited for this purpose. Other applicable approaches include majority voting or <a href="https://en.wikipedia.org/wiki/Conditional_random_field">Conditional Random Fields (CRF)</a>. SLIC is modified K-means algorithm, where the relative importance of spatial and color distances can be controlled with a compacity parameter. Matlab users who have access to the image processing toolbox can use the <code>superpixels()</code> function. Octave users (or Matlab users who dot not have the image processing toolbox) have to compile the SLICmex.c function provided by Achanta et al. (and included in the external functions directory of the Digital Forestry Toolbox), by typing the following line in the command window:</p>
        
        <pre><code>mex slicmex.c</code></pre>
        
            <pre><code>% convert NaN values to zero
I_first(isnan(I_first)) = 0;

% rescale values to an 8 bit range (0-255)
I_first_n = (I_first - quantile(I_first(:), 0.02)) ./ diff(quantile(I_first(:), [0.02, 0.98]));
I_first_n = uint8(I_first_n * 255);


if OCTAVE_FLAG
    
    % before running slicmex, you have to compile it with the following command:
    % mex slicmex.c
    [L, nlabels] = slicmex(I_first_n, 15000, 100);
    
else
    
    [L, nlabels] = superpixels(I_first, 18000, 'Compactness', 30);
    
end</code></pre>

   
            <h2>
                <a id="step-5" class="anchor" href="step-5" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><b>Step 5</b> - Compute segment level intensity
            </h2>

            <p>You can write the stem attributes to a Comma Separated Values text file (.csv) with:</p>

            <pre><code>I_first_s = accumarray(L(:)+1, I_first(:), [nrows*ncols,1], @nanmean, nan);
I_first_s = I_first_s(L+1);</code></pre>

<pre><code>figure
imagesc(I_first_s)
axis equal tight
colorbar
caxis(quantile(I_first_s(:), [0.02, 0.98]))</code></pre>

     
            <h2>
                <a id="step-6" class="anchor" href="step-6" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><b>Step 6</b> - Create a classification map
            </h2>

            <p>To export the stem attributes to an ESRI shapefile, you first have to format them into a non-scalar structure and add a "Geometry" field:</p>

            <pre><code>S = struct;
for j = 1:size(xyh_stem,1)

    S(j,1).Geometry = 'Point';
    S(j,1).BoundingBox = [];
    S(j,1).ID = j;
    S(j,1).X = xyh_stem(j,1);
    S(j,1).Y = xyh_stem(j,2);
    S(j,1).H = xyh_stem(j,3);

end</code></pre>

            <p>Specify the output filepath (by default, the file is created in the current working directory) and use <code>shapewrite()</code> to write the file:</p>

            <pre><code>shapewrite(S, 'ge_2017_a_stems.shp');</code></pre>

            <p>After exporting the shapefile, you can try opening it in any GIS software (e.g. <a href="http://www.qgis.org">Quantum GIS</a>).</p>

            
            <p>By modifing the parameters values, you can adjust the tradeoff between the sensitivity (recall) and the reliability (precision) of the detection. The interactive map below illustrates the detected stem positions. The results could also be refined the . Use the layer switcher to compare different map layers (aerial photography, intensity map, classification map).</p>

            <div id="map2"></div>

<!--            <h2>
                <a id="step-7" class="anchor" href="step-7" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><b>Step 7</b> - Validate the results
            </h2>-->
        
            <h2>
                <a id="references" class="anchor" href="references" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><b>References</b>
            </h2>

            <ul>

                <li>Achanta, R., Shaji, A., Smith, K., Lucchi, A., Fua, P., Süsstrunk, S., 2012. <a href="https://ivrl.epfl.ch/research-2/research-current/research-superpixels/">SLIC Superpixels Compared to State-of-the-Art Superpixel Methods</a>. IEEE Transactions on Pattern Analysis and Machine Intelligence 34, 2274–2282. https://doi.org/10.1109/TPAMI.2012.120</li>

                <li>Kashani, A.G., Olsen, M.J., Parrish, C.E., Wilson, N., 2015. <a href="https://www.mdpi.com/1424-8220/15/11/28099">A Review of LIDAR Radiometric Processing: From Ad Hoc Intensity Correction to Rigorous Radiometric Calibration</a>. Sensors 15, 28099–28128. https://doi.org/10.3390/s151128099</li>

                <li>Liang, X., Hyyppä, J., Matikainen, L., 2007. <a href="http://www.isprs.org/proceedings/XXXVI/3-W52/final_papers/Liang_2007.pdf">Deciduous-coniferous tree classification using difference between first and last pulse laser signatures</a>. International Archives of Photogrammetry, Remote Sensing and Spatial Information Sciences 36, 253–257.</li>

                <li>Luzum, B., Starek, M., Slatton, K.C., 2004. <a href="https://www.researchgate.net/publication/266228111_Normalizing_ALSM_Intensities">Normalizing ALSM intensities (No. Rep_2004-07-01)</a>, Geosensing Engineering and Mapping (GEM) Center. Civil and Coastal Engineering Department, University of Florida, Gainesville, FL, USA.</li>

                <li>Ørka, H. O., Næsset, E., Bollandsås, O. M., Jun. 2009. <a href="https://www.sciencedirect.com/science/article/abs/pii/S0034425709000376">Classifying species of individual trees by intensity and structure features derived from airborne laser scanner data</a>. Remote Sensing of Environment 113 (6), 1163–1174.</li>
                
                <li>Riegl Laser Measurement Systems, 2017. <a href="http://www.riegl.com/uploads/tx_pxpriegldownloads/Whitepaper_LASextrabytes_implementation_in-RIEGLSoftware_2017-12-04.pdf">LAS Extrabytes Implementation in RIEGL Software</a>. Riegl Laser Measurement Systems GmbH, Horn, Riedenburgstrasse 48, Austria.</li>

                <li>Shi, Y., Wang, T., Skidmore, A. K., Heurich, M., Mar. 2018b. <a href="https://www.sciencedirect.com/science/article/abs/pii/S0924271618300315">Important LiDAR metrics for discriminating forest tree species in Central Europe</a>. ISPRS Journal of Photogrammetry and Remote Sensing 137, 163–174.</li>
                
                <li>Vain, A., Kaasalainen, S., 2011. <a href="http://cdn.intechopen.com/pdfs/15799/InTech-Correcting_airborne_laser_scanning_intensity_data.pdf">Correcting airborne laser scanning intensity data</a>. INTECH Open Access Publisher.</li>

            </ul>

            <footer class="site-footer">
                <span class="site-footer-owner"><a href="https://github.com/mparkan/Digital-Forestry-Toolbox">Digital-forestry-toolbox</a> is maintained by <a href="https://github.com/mparkan">mparkan</a>.</span>

            </footer>

        </section>

        <script>

            // add CH1903 and CH1903+ CRS definitions
            if (proj4) {
                proj4.defs("EPSG:21781","+proj=somerc +lat_0=46.95240555555556 +lon_0=7.439583333333333 +k_0=1 +x_0=600000 +y_0=200000 +ellps=bessel +towgs84=674.4,15.1,405.3,0,0,0,0 +units=m +no_defs");
                proj4.defs("EPSG:2056", "+proj=somerc +lat_0=46.95240555555556 +lon_0=7.439583333333333 +k_0=1 +x_0=2600000 +y_0=1200000 +ellps=bessel +towgs84=674.374,15.056,405.346,0,0,0,0 +units=m +no_defs");
                ol.proj.proj4.register(proj4);
            };

            // define tile grid
            var extent = [2499100.0000000000000000,1127220.0000000000000000, 2499780.0000000000000000,1127900.0000000000000000]; // [minx, miny, maxx, maxy].
            var minZoom = 0;
            var maxZoom = 5;
            var startResolution = (extent[2]-extent[0]) / 256;
            var pixelResolutions = new Array(maxZoom + 1);
            for (var i = 0, ii = pixelResolutions.length; i < ii; ++i) {
                pixelResolutions[i] = startResolution / Math.pow(2, i);
            }
            var mapTileGrid = new ol.tilegrid.TileGrid({
                extent: extent,
                resolutions: pixelResolutions
            });

/*            // define vector layer
            var vectorLayer1 = new ol.layer.Vector({
                title: 'Tree tops',
                type: 'overlay',
                source: new ol.source.Vector({
                    format: new ol.format.GeoJSON(),
                    url: 'http://mparkan.github.io/Digital-Forestry-Toolbox/data/tutorial_2/vector/zh_2014_a_peaks.geojson',
                    crossOrigin: 'anonymous',
                    projection: 'EPSG:2056',
                }),
                style: new ol.style.Style({
                    image: new ol.style.Circle( ({
                        radius: 2,
                        fill: new ol.style.Fill({
                            color: '#ffff00'
                        })
                    }))
                })
            });*/
            
            // define XYZ tiles layer
            var rasterTileLayer1 = new ol.layer.Tile({
                title: 'RGB image',
                type: 'base',
                source: new ol.source.XYZ({
                    url: 'http://mparkan.github.io/Digital-Forestry-Toolbox/data/tutorial_3/raster/ortho/{z}/{x}/{y}.jpg',
                    crossOrigin: 'anonymous',
                    tileGrid: mapTileGrid,
                    projection: 'EPSG:2056',
                    opaque: false,
                    attributions: ['Data courtesy of <a href=https://ge.ch/sitg/donnees>Geneva</a>']
                })
            });

            
            // define static image layer
            var rasterStaticLayer1 = new ol.layer.Image({
                title: 'First return intensity',
                type: 'base',
                source: new ol.source.ImageStatic({
                    url: 'http://mparkan.github.io/Digital-Forestry-Toolbox/data/tutorial_4/raster/ge_2017_a_intensity.png',
                    crossOrigin: 'anonymous',
                    projection: 'EPSG:2056',
                    imageSize: [681,681],
                    imageExtent: extent,
                    attributions: 'Data courtesy of <a href=https://ge.ch/sitg/donnees>Geneva</a>'
                })
            });
            
            
            // define static image layer
            var rasterStaticLayer2 = new ol.layer.Image({
                title: 'Classification',
                type: 'base',
                source: new ol.source.ImageStatic({
                    url: 'http://mparkan.github.io/Digital-Forestry-Toolbox/data/tutorial_4/raster/ge_2017_a_class.png',
                    crossOrigin: 'anonymous',
                    projection: 'EPSG:2056',
                    imageSize: [681,681],
                    imageExtent: extent,
                    attributions: 'Data courtesy of <a href=https://ge.ch/sitg/donnees>Geneva</a>'
                })
            });
            
            
            // define scale bar control
            var scaleLineControl = new ol.control.ScaleLine();

            // define attribution control
            var attributionControl = new ol.control.Attribution({
                collapsible: true,
                className: 'ol-attribution'
            });

            // define fullscreen control
            var icon1 = document.createElement("expand_icon");
            icon1.className = "fa fa-expand";

            var fullScreenControl = new ol.control.FullScreen({
                label: icon1
            });

            // layer switcher control
            var layerSwitcherControl = new ol.control.LayerSwitcher({
                tipLabel: 'Layers'
            });


            var layerGroup1 = new ol.layer.Group({
                title: 'Basemaps',
                layers: [
                    rasterTileLayer1,
                    rasterStaticLayer1,
                    rasterStaticLayer2
                ]
            });


/*            var layerGroup2 = new ol.layer.Group({
                title: 'Overlays',
                layers: [
                    vectorLayer1
                ]
            });*/


            // initialize map
            var map = new ol.WebGLMap({
                target: 'map2',
                controls: ol.control.defaults({attribution: false}).extend([
                    scaleLineControl,
                    attributionControl,
                    fullScreenControl,
                    layerSwitcherControl
                ]),
                interactions: ol.interaction.defaults().extend([
                    new ol.interaction.DragRotateAndZoom()
                ]),
                layers: [
                    layerGroup1
                ],
                view: new ol.View({
                    extent: extent,
                    center: ol.extent.getCenter(extent),
                    projection: ol.proj.get('EPSG:2056'),
                    zoom: 2,
                    minZoom: 1,
                    maxZoom: 6,
                    maxResolution: mapTileGrid.getResolution(minZoom)
                })
            });


        </script>

    </body>

</html>
